{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "#import package\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pylab as plt\n",
    "import time\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "\n",
    "from keras import optimizers\n",
    "#%matplotlib inline\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "def readData():\n",
    "    data = pd.read_csv('C:/Users/yoon/Python/Stock_Prediction/Samsung_20_DIV.csv', parse_dates = [0])\n",
    "    raw_dates = data.loc[30:, 'date'].reset_index(drop=True)\n",
    "    del data['date']\n",
    "    raw_data = data.loc[30:].reset_index(drop=True)\n",
    "    return raw_data, raw_dates\n",
    "\n",
    "def split_into_chunks(data, train, predict, step):\n",
    "    train_set, label_set = [], []\n",
    "    for i in range(0, len(data), step):\n",
    "        try:\n",
    "            temp_train = data.loc[i:i+train-1, 'dSMA':'dCCI']\n",
    "            temp_train = preprocessing.scale(temp_train)\n",
    "            temp_label = data.loc[i+train-1+predict, 'return']\n",
    "            if temp_label >= 0 :\n",
    "                 temp_label = [1., 0.]\n",
    "            else:\n",
    "                 temp_label = [0., 1.]\n",
    "        except:\n",
    "            break\n",
    "        train_set.append(temp_train)\n",
    "        label_set.append(temp_label)\n",
    "    return train_set, label_set\n",
    "\n",
    "def shuffle_in_unison(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    rng_state = np.random.get_state()\n",
    "    np.random.shuffle(a)\n",
    "    np.random.set_state(rng_state)\n",
    "    np.random.shuffle(b)\n",
    "    return a, b\n",
    "\n",
    "def create_Xt_Yt(X, y, percentage=0.5):\n",
    "    X_train = X[0:int(len(X) * percentage)]\n",
    "    Y_train = y[0:int(len(y) * percentage)]\n",
    "    X_train, Y_train = shuffle_in_unison(X_train, Y_train)\n",
    "    X_test = X[int(len(X) * percentage):]\n",
    "    Y_test = y[int(len(X) * percentage):]\n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "timeSeriesList, dates = readData()\n",
    "\n",
    "DATA_SIZE_ON_TRAIN = 30\n",
    "TARGET_TIME = 1\n",
    "STEP_SIZE = 1\n",
    "EMB_SIZE = 10\n",
    "\n",
    "X, Y = split_into_chunks(timeSeriesList, DATA_SIZE_ON_TRAIN, TARGET_TIME, STEP_SIZE)\n",
    "X, Y = np.array(X), np.array(Y)\n",
    "X_train, X_test, Y_train, Y_test = create_Xt_Yt(X, Y, percentage=0.5)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch 1/100\n",
      "2579/2579 [==============================] - 20s - loss: 4.6594 - acc: 0.4827    \n",
      "Epoch 2/100\n",
      "1792/2579 [===================>..........] - ETA: 2s - loss: 4.7236 - acc: 0.4911"
     ]
    }
   ],
   "source": [
    "#reshape (#samples, #time steps(time series), #feature)\n",
    "#X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], EMB_SIZE))\n",
    "#X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], EMB_SIZE))\n",
    "model = Sequential()\n",
    "\n",
    "#input_shape = (#time step, #feature)\n",
    "model.add(LSTM(50, input_shape = (DATA_SIZE_ON_TRAIN, EMB_SIZE), dropout = 0.5, return_sequences=True))\n",
    "model.add(LSTM(2, return_sequences=False))\n",
    "\n",
    "adam = optimizers.Adam(lr=0.1)\n",
    "\n",
    "model.compile(optimizer=adam,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(\"Training...\")\n",
    "model.fit(X_train, \n",
    "          Y_train, \n",
    "          epochs=100, \n",
    "          batch_size = 128,\n",
    "          verbose=1)\n",
    "\n",
    "print(\"Evaluating...\")\n",
    "score = model.evaluate(X_test, Y_test, batch_size=128)\n",
    "print(\"\\nTest loss and accuracy:\" + str(score))\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
